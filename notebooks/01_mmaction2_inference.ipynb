{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b3a0090-540a-40f9-be15-d6f9d030f983",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom mmaction.apis.inferencers import MMAction2Inferencer\\ninferencer = MMAction2Inferencer(rec='tsn')\\nresult = inferencer(input_video_path)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "from mmaction.apis.inferencers import MMAction2Inferencer\n",
    "inferencer = MMAction2Inferencer(rec='tsn')\n",
    "result = inferencer(input_video_path)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3029b2a0-2dc5-4f9c-918c-01b3386da470",
   "metadata": {},
   "source": [
    "# Tsn demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6273280-94ff-4244-ade1-181354064d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from mmaction.apis import init_recognizer, inference_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b4e828f-6c3d-4fda-8576-537d7807a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../demo/demo_configs/tsn_r50_1x1x8_video_infer.py'\n",
    "# download the checkpoint from model zoo and put it in `checkpoints/`\n",
    "checkpoint_file = '../checkpoints/tsn_r50_8xb32-1x1x8-100e_kinetics400-rgb_20220818-2692d16c.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8e9038e3-f927-4eb3-916f-ad25abed7b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../checkpoints/tsn_r50_8xb32-1x1x8-100e_kinetics400-rgb_20220818-2692d16c.pth\n"
     ]
    }
   ],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "model = init_recognizer(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5cf0d11-cebf-4c42-9ba8-f8bd4ceb306c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test a single video and show the result:\n",
    "video = 'demo.mp4'\n",
    "label = '../tools/data/kinetics/label_map_k400.txt'\n",
    "results = inference_recognizer(model, video)\n",
    "\n",
    "pred_scores = results.pred_score.tolist()\n",
    "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
    "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
    "top5_label = score_sorted[:5]\n",
    "\n",
    "labels = open(label).readlines()\n",
    "labels = [x.strip() for x in labels]\n",
    "results = [(labels[k[0]], k[1]) for k in top5_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6927d1eb-6034-414c-ba93-2aa171bf7419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arm wrestling:  1.0\n",
      "rock scissors paper:  1.692707041902968e-15\n",
      "massaging feet:  5.181661586148322e-16\n",
      "stretching leg:  1.0245810453406013e-16\n",
      "bench pressing:  7.173414165944793e-17\n"
     ]
    }
   ],
   "source": [
    "# show the results\n",
    "for result in results:\n",
    "    print(f'{result[0]}: ', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f0edad-9e31-4b73-9a86-c2a247870db3",
   "metadata": {},
   "source": [
    "# Tsn ucf101\n",
    "\n",
    "python tools/test.py configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_ucf101-rgb.py \\\n",
    "    work_dirs/ucf101_tsn/epoch_100.pth --work-dir ./work_dirs/ucf101_tsn --dump result.pkl\n",
    "\n",
    "    \"\"\"python\n",
    "    10/24 11:20:29 - mmengine - INFO - Epoch(test) [3783/3783]    acc/top1: 0.8369  acc/top5: 0.9633  acc/mean1: 0.8353  data_time: 0.0120  time: 0.1183\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3126783d-4d70-458f-b716-11005ddd2ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from mmaction.apis import init_recognizer, inference_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "453e132f-e124-4d71-80ae-78475128e15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../demo/demo_configs/tsn_r50_1x1x8_video_infer.py'\n",
    "# download the checkpoint from model zoo and put it in `checkpoints/`\n",
    "checkpoint_file = '../work_dirs/ucf101_tsn/epoch_100.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a2011150-860b-492d-9a47-0a1129560a42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../work_dirs/ucf101_tsn/epoch_100.pth\n"
     ]
    }
   ],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "model = init_recognizer(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "14ec0d0e-cdbe-4836-83cf-b3679e0a9090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top5_label: [(0, 0.8964292407035828), (1, 0.10238026082515717), (19, 0.0011066367151215672), (62, 2.2247249944484793e-05), (33, 1.5841680578887463e-05)]\n",
      "labels: ['ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam', 'BandMarching', 'BaseballPitch', 'Basketball', 'BasketballDunk', 'BenchPress', 'Biking', 'Billiards', 'BlowDryHair', 'BlowingCandles', 'BodyWeightSquats', 'Bowling', 'BoxingPunchingBag', 'BoxingSpeedBag', 'BreastStroke', 'BrushingTeeth', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'CuttingInKitchen', 'Diving', 'Drumming', 'Fencing', 'FieldHockeyPenalty', 'FloorGymnastics', 'FrisbeeCatch', 'FrontCrawl', 'GolfSwing', 'Haircut', 'Hammering', 'HammerThrow', 'HandstandPushups', 'HandstandWalking', 'HeadMassage', 'HighJump', 'HorseRace', 'HorseRiding', 'HulaHoop', 'IceDancing', 'JavelinThrow', 'JugglingBalls', 'JumpingJack', 'JumpRope', 'Kayaking', 'Knitting', 'LongJump', 'Lunges', 'MilitaryParade', 'Mixing', 'MoppingFloor', 'Nunchucks', 'ParallelBars', 'PizzaTossing', 'PlayingCello', 'PlayingDaf', 'PlayingDhol', 'PlayingFlute', 'PlayingGuitar', 'PlayingPiano', 'PlayingSitar', 'PlayingTabla', 'PlayingViolin', 'PoleVault', 'PommelHorse', 'PullUps', 'Punch', 'PushUps', 'Rafting', 'RockClimbingIndoor', 'RopeClimbing', 'Rowing', 'SalsaSpin', 'ShavingBeard', 'Shotput', 'SkateBoarding', 'Skiing', 'Skijet', 'SkyDiving', 'SoccerJuggling', 'SoccerPenalty', 'StillRings', 'SumoWrestling', 'Surfing', 'Swing', 'TableTennisShot', 'TaiChi', 'TennisSwing', 'ThrowDiscus', 'TrampolineJumping', 'Typing', 'UnevenBars', 'VolleyballSpiking', 'WalkingWithDog', 'WallPushups', 'WritingOnBoard', 'YoYo']\n"
     ]
    }
   ],
   "source": [
    "# test a single video and show the result:\n",
    "# video = 'demo.mp4'\n",
    "video = '../data/ucf101/videos/ApplyEyeMakeup/v_ApplyEyeMakeup_g01_c01.avi'\n",
    "# label = '../tools/data/kinetics/label_map_k400.txt'\n",
    "label = '../tools/data/ucf101/label_map.txt'\n",
    "results = inference_recognizer(model, video)\n",
    "\n",
    "pred_scores = results.pred_score.tolist()\n",
    "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
    "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
    "top5_label = score_sorted[:5]\n",
    "print(f\"top5_label: {top5_label}\")\n",
    "\n",
    "labels = open(label).readlines()\n",
    "labels = [x.strip() for x in labels]\n",
    "print(f\"labels: {labels}\")\n",
    "results = [(labels[k[0]], k[1]) for k in top5_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "100946c1-1be7-460f-93c1-b8d45a7df624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ApplyEyeMakeup:  0.8964292407035828\n",
      "ApplyLipstick:  0.10238026082515717\n",
      "BrushingTeeth:  0.0011066367151215672\n",
      "PlayingGuitar:  2.2247249944484793e-05\n",
      "Haircut:  1.5841680578887463e-05\n"
     ]
    }
   ],
   "source": [
    "# show the results\n",
    "for result in results:\n",
    "    print(f'{result[0]}: ', result[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "846fb34a-efa4-4243-8094-1f59b17551a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3783 results.\n",
      "First result: {'img_shape': (224, 224), 'num_classes': 101, 'gt_label': tensor([59]), 'pred_score': tensor([1.1258e-05, 1.8924e-04, 2.6743e-04, 1.0788e-05, 1.2404e-06, 1.1548e-04,\n",
      "        1.0481e-05, 3.4778e-05, 1.2205e-04, 4.2414e-05, 4.9440e-06, 2.4979e-05,\n",
      "        5.6382e-05, 8.5170e-05, 2.5579e-03, 5.9897e-05, 8.6674e-05, 2.5675e-04,\n",
      "        4.7430e-06, 2.4132e-05, 6.2747e-04, 9.2840e-06, 4.1179e-06, 1.2592e-04,\n",
      "        1.2167e-05, 4.5906e-06, 1.5295e-02, 6.1782e-06, 5.8258e-05, 2.0531e-06,\n",
      "        4.8335e-05, 5.2230e-06, 3.6419e-05, 2.1750e-04, 1.3819e-05, 9.2479e-05,\n",
      "        1.8767e-05, 1.0948e-05, 1.7376e-05, 3.7806e-06, 7.0130e-06, 4.8836e-05,\n",
      "        7.5889e-05, 1.2174e-05, 3.3303e-06, 5.1804e-03, 2.6118e-04, 3.6313e-04,\n",
      "        1.3945e-05, 3.6954e-06, 5.3370e-06, 2.2423e-05, 1.4328e-05, 4.8323e-04,\n",
      "        5.5634e-05, 1.0016e-04, 5.9534e-05, 1.3487e-04, 5.9004e-03, 9.5817e-01,\n",
      "        2.7552e-04, 1.6373e-03, 2.5571e-04, 7.6034e-05, 9.0559e-05, 2.9805e-04,\n",
      "        1.7642e-05, 6.7160e-06, 4.0806e-05, 6.8924e-05, 1.4882e-04, 1.8186e-04,\n",
      "        2.5508e-05, 1.6410e-06, 4.3573e-05, 1.1874e-05, 4.4128e-05, 7.0361e-05,\n",
      "        1.7979e-04, 2.2409e-05, 2.0777e-05, 7.2348e-06, 5.8041e-06, 2.8817e-04,\n",
      "        1.8462e-05, 5.9557e-06, 2.3105e-05, 8.4220e-05, 2.6415e-08, 2.6176e-03,\n",
      "        1.2155e-04, 5.5770e-05, 1.1900e-03, 3.7769e-05, 6.9342e-05, 1.3247e-05,\n",
      "        8.3074e-06, 1.1202e-06, 2.4972e-04, 1.1434e-04, 7.8021e-05]), 'pred_label': tensor([59])}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# 读取 pkl 文件\n",
    "with open('../result.pkl', 'rb') as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "# 查看结果\n",
    "print(f\"Loaded {len(results)} results.\")\n",
    "print(f\"First result: {results[0]}\")  # 打印第一个样本的结果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f3449d-a0de-4984-a4d5-7ab487a4ddda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1a74fb35-6364-4b6f-baf8-57be80734469",
   "metadata": {},
   "source": [
    "# slowfast ucf101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "0d1e610d-9988-4ce3-a2ea-6ddc4686c7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from mmaction.apis import init_recognizer, inference_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0f496e4b-c3e8-4b8a-9e4f-b24be1511807",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../demo/demo_configs/slowfast_video_infer.py'\n",
    "# download the checkpoint from model zoo and put it in `checkpoints/`\n",
    "checkpoint_file = '../work_dirs/ucf101_slowfast/epoch_256.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "5d8b4000-7525-47bd-9f93-14c83cac26b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../work_dirs/ucf101_slowfast/epoch_256.pth\n"
     ]
    }
   ],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "model = init_recognizer(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "19cef497-0bb9-4dc1-82a3-2412cb5a56e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top5_label: [(3, 0.9995399713516235), (29, 0.00015323185652960092), (55, 0.00013078315532766283), (65, 3.969498357037082e-05), (13, 3.046785423066467e-05)]\n",
      "labels: ['ApplyEyeMakeup', 'ApplyLipstick', 'Archery', 'BabyCrawling', 'BalanceBeam', 'BandMarching', 'BaseballPitch', 'Basketball', 'BasketballDunk', 'BenchPress', 'Biking', 'Billiards', 'BlowDryHair', 'BlowingCandles', 'BodyWeightSquats', 'Bowling', 'BoxingPunchingBag', 'BoxingSpeedBag', 'BreastStroke', 'BrushingTeeth', 'CleanAndJerk', 'CliffDiving', 'CricketBowling', 'CricketShot', 'CuttingInKitchen', 'Diving', 'Drumming', 'Fencing', 'FieldHockeyPenalty', 'FloorGymnastics', 'FrisbeeCatch', 'FrontCrawl', 'GolfSwing', 'Haircut', 'Hammering', 'HammerThrow', 'HandstandPushups', 'HandstandWalking', 'HeadMassage', 'HighJump', 'HorseRace', 'HorseRiding', 'HulaHoop', 'IceDancing', 'JavelinThrow', 'JugglingBalls', 'JumpingJack', 'JumpRope', 'Kayaking', 'Knitting', 'LongJump', 'Lunges', 'MilitaryParade', 'Mixing', 'MoppingFloor', 'Nunchucks', 'ParallelBars', 'PizzaTossing', 'PlayingCello', 'PlayingDaf', 'PlayingDhol', 'PlayingFlute', 'PlayingGuitar', 'PlayingPiano', 'PlayingSitar', 'PlayingTabla', 'PlayingViolin', 'PoleVault', 'PommelHorse', 'PullUps', 'Punch', 'PushUps', 'Rafting', 'RockClimbingIndoor', 'RopeClimbing', 'Rowing', 'SalsaSpin', 'ShavingBeard', 'Shotput', 'SkateBoarding', 'Skiing', 'Skijet', 'SkyDiving', 'SoccerJuggling', 'SoccerPenalty', 'StillRings', 'SumoWrestling', 'Surfing', 'Swing', 'TableTennisShot', 'TaiChi', 'TennisSwing', 'ThrowDiscus', 'TrampolineJumping', 'Typing', 'UnevenBars', 'VolleyballSpiking', 'WalkingWithDog', 'WallPushups', 'WritingOnBoard', 'YoYo']\n"
     ]
    }
   ],
   "source": [
    "# test a single video and show the result:\n",
    "# video = 'demo.mp4'\n",
    "video = '../data/ucf101/videos/BabyCrawling/v_BabyCrawling_g09_c04.avi'\n",
    "# label = '../tools/data/kinetics/label_map_k400.txt'\n",
    "label = '../tools/data/ucf101/label_map.txt'\n",
    "results = inference_recognizer(model, video)\n",
    "\n",
    "pred_scores = results.pred_score.tolist()\n",
    "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
    "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
    "top5_label = score_sorted[:5]\n",
    "print(f\"top5_label: {top5_label}\")\n",
    "\n",
    "labels = open(label).readlines()\n",
    "labels = [x.strip() for x in labels]\n",
    "print(f\"labels: {labels}\")\n",
    "results = [(labels[k[0]], k[1]) for k in top5_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "071a02fe-c033-4699-bc10-41716348c348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BabyCrawling:  0.9995399713516235\n",
      "FloorGymnastics:  0.00015323185652960092\n",
      "Nunchucks:  0.00013078315532766283\n",
      "PlayingTabla:  3.969498357037082e-05\n",
      "BlowingCandles:  3.046785423066467e-05\n"
     ]
    }
   ],
   "source": [
    "# show the results\n",
    "for result in results:\n",
    "    print(f'{result[0]}: ', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4edfb19-d855-4c39-b274-ff79e5e75945",
   "metadata": {},
   "source": [
    "# slowfast xian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d8d4a23e-73bb-4b7f-9f13-7ca6ca573dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from mmaction.apis import init_recognizer, inference_recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7f240ce6-16bb-4154-a825-c2b93db2d7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = '../demo/demo_configs/slowfast_video_infer.py'\n",
    "# download the checkpoint from model zoo and put it in `checkpoints/`\n",
    "checkpoint_file = '../work_dirs/xiandemo_slowfast/epoch_256.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d6dd3882-b6cb-4abd-9f82-5b698d91e1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../work_dirs/xiandemo_slowfast/epoch_256.pth\n"
     ]
    }
   ],
   "source": [
    "# build the model from a config file and a checkpoint file\n",
    "model = init_recognizer(config_file, checkpoint_file, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f9a60955-f90a-49cf-ae21-d9cf36c9f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top5_label: [(2, 0.9999839067459106), (1, 9.942761607817374e-06), (4, 4.7818434723012615e-06), (3, 1.3897634971726802e-06), (0, 6.877859703990907e-08)]\n",
      "labels: ['en', 'na', 'si', 'tie', 'zhuan']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "# test a single video and show the result:\n",
    "# video = 'demo.mp4'\n",
    "video = '../data/xian_video_dataset/val/3 (35).mp4'\n",
    "# label = '../tools/data/kinetics/label_map_k400.txt'\n",
    "label = '../data/xian_video_dataset/label_map.txt'\n",
    "\n",
    "results = inference_recognizer(model, video)\n",
    "\n",
    "pred_scores = results.pred_score.tolist()\n",
    "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
    "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
    "top5_label = score_sorted[:5]\n",
    "print(f\"top5_label: {top5_label}\")\n",
    "\n",
    "labels = open(label).readlines()\n",
    "labels = [x.strip() for x in labels]\n",
    "print(f\"labels: {labels}\")\n",
    "results = [(labels[k[0]], k[1]) for k in top5_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "00d47399-10c4-415b-ba8f-86990045dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "si:  0.9999839067459106\n",
      "na:  9.942761607817374e-06\n",
      "zhuan:  4.7818434723012615e-06\n",
      "tie:  1.3897634971726802e-06\n",
      "en:  6.877859703990907e-08\n"
     ]
    }
   ],
   "source": [
    "# show the results\n",
    "for result in results:\n",
    "    print(f'{result[0]}: ', result[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c770b75e-df2b-4c0f-979f-412673661cd8",
   "metadata": {},
   "source": [
    "## video show 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3fb4158b-ea1a-4801-9b55-1d6ce3dd2f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom mmaction.apis.inferencers import MMAction2Inferencer\\ninferencer = MMAction2Inferencer(rec='tsn')\\nresult = inferencer(input_video_path)\\n\""
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from mmaction.apis.inferencers import MMAction2Inferencer\n",
    "inferencer = MMAction2Inferencer(rec='tsn')\n",
    "result = inferencer(input_video_path)\n",
    "\n",
    "python demo/demo_inferencer.py demo/demo.mp4 \n",
    "--rec tsn \n",
    "--rec-weights checkpoints/tsn_imagenet-pretrained-r50_8xb32-1x1x8-100e_kinetics400-rgb_20220906-2692d16c.pth \n",
    "--label-file tools/data/kinetics/label_map_k400.txt \n",
    "--vid-out-dir demo_out\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "9d646e2f-3145-4ca9-9e4b-ef203a833fab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../work_dirs/xiandemo_slowfast/epoch_256.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0643a00eeb6e44d69ee33e319030b15c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [{'rec_labels': [[1]], 'rec_scores': [[0.007289442233741283, 0.9150851964950562, 0.0666770488023758, 0.01027526892721653, 0.0006730405730195343]]}]}\n",
      "{'predictions': [{'rec_labels': [[1]], 'rec_scores': [[0.007289442233741283, 0.9150851964950562, 0.0666770488023758, 0.01027526892721653, 0.0006730405730195343]]}], 'visualization': [array([[[[ 45,  41,  32],\n",
      "         [ 45,  41,  32],\n",
      "         [ 50,  46,  37],\n",
      "         ...,\n",
      "         [155, 175, 168],\n",
      "         [155, 175, 168],\n",
      "         [159, 179, 172]],\n",
      "\n",
      "        [[ 63,  58,  52],\n",
      "         [ 63,  58,  52],\n",
      "         [ 59,  54,  48],\n",
      "         ...,\n",
      "         [155, 175, 168],\n",
      "         [155, 175, 168],\n",
      "         [160, 180, 173]],\n",
      "\n",
      "        [[106, 101,  95],\n",
      "         [107, 102,  96],\n",
      "         [101,  96,  90],\n",
      "         ...,\n",
      "         [155, 175, 168],\n",
      "         [156, 176, 169],\n",
      "         [160, 180, 173]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[201, 206, 202],\n",
      "         [201, 206, 202],\n",
      "         [201, 206, 202],\n",
      "         ...,\n",
      "         [147, 164, 194],\n",
      "         [147, 164, 194],\n",
      "         [148, 164, 196]],\n",
      "\n",
      "        [[201, 206, 202],\n",
      "         [201, 206, 202],\n",
      "         [201, 206, 202],\n",
      "         ...,\n",
      "         [146, 163, 193],\n",
      "         [149, 166, 196],\n",
      "         [149, 166, 196]],\n",
      "\n",
      "        [[201, 206, 202],\n",
      "         [201, 206, 202],\n",
      "         [201, 206, 202],\n",
      "         ...,\n",
      "         [146, 163, 193],\n",
      "         [149, 166, 196],\n",
      "         [149, 166, 196]]],\n",
      "\n",
      "\n",
      "       [[[ 69,  64,  52],\n",
      "         [ 76,  71,  59],\n",
      "         [ 75,  70,  58],\n",
      "         ...,\n",
      "         [153, 174, 169],\n",
      "         [155, 176, 171],\n",
      "         [160, 181, 176]],\n",
      "\n",
      "        [[ 92,  86,  77],\n",
      "         [ 99,  93,  84],\n",
      "         [102,  96,  87],\n",
      "         ...,\n",
      "         [153, 174, 169],\n",
      "         [155, 176, 171],\n",
      "         [161, 182, 177]],\n",
      "\n",
      "        [[ 87,  81,  72],\n",
      "         [ 91,  85,  76],\n",
      "         [ 97,  91,  82],\n",
      "         ...,\n",
      "         [153, 174, 169],\n",
      "         [156, 177, 172],\n",
      "         [161, 182, 177]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[202, 207, 203],\n",
      "         [202, 207, 203],\n",
      "         [202, 207, 203],\n",
      "         ...,\n",
      "         [139, 164, 194],\n",
      "         [140, 165, 195],\n",
      "         [140, 165, 197]],\n",
      "\n",
      "        [[202, 207, 203],\n",
      "         [202, 207, 203],\n",
      "         [202, 207, 203],\n",
      "         ...,\n",
      "         [138, 163, 193],\n",
      "         [139, 164, 194],\n",
      "         [140, 165, 197]],\n",
      "\n",
      "        [[202, 207, 203],\n",
      "         [202, 207, 203],\n",
      "         [202, 207, 203],\n",
      "         ...,\n",
      "         [138, 163, 193],\n",
      "         [139, 164, 194],\n",
      "         [140, 165, 197]]],\n",
      "\n",
      "\n",
      "       [[[ 94,  88,  86],\n",
      "         [ 89,  83,  81],\n",
      "         [ 93,  87,  85],\n",
      "         ...,\n",
      "         [154, 175, 172],\n",
      "         [158, 179, 176],\n",
      "         [160, 181, 178]],\n",
      "\n",
      "        [[ 93,  86,  86],\n",
      "         [ 93,  86,  86],\n",
      "         [ 94,  87,  87],\n",
      "         ...,\n",
      "         [154, 175, 172],\n",
      "         [158, 179, 176],\n",
      "         [160, 181, 178]],\n",
      "\n",
      "        [[ 72,  65,  65],\n",
      "         [ 76,  69,  69],\n",
      "         [ 79,  72,  72],\n",
      "         ...,\n",
      "         [155, 176, 173],\n",
      "         [158, 179, 176],\n",
      "         [160, 181, 178]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[198, 208, 203],\n",
      "         [198, 208, 203],\n",
      "         [198, 208, 203],\n",
      "         ...,\n",
      "         [145, 161, 195],\n",
      "         [146, 162, 196],\n",
      "         [148, 164, 198]],\n",
      "\n",
      "        [[197, 207, 202],\n",
      "         [197, 207, 202],\n",
      "         [197, 207, 202],\n",
      "         ...,\n",
      "         [145, 161, 195],\n",
      "         [146, 162, 196],\n",
      "         [148, 164, 198]],\n",
      "\n",
      "        [[197, 207, 202],\n",
      "         [197, 207, 202],\n",
      "         [197, 207, 202],\n",
      "         ...,\n",
      "         [145, 161, 195],\n",
      "         [146, 162, 196],\n",
      "         [148, 164, 198]]],\n",
      "\n",
      "\n",
      "       ...,\n",
      "\n",
      "\n",
      "       [[[201, 202, 198],\n",
      "         [211, 212, 208],\n",
      "         [201, 202, 198],\n",
      "         ...,\n",
      "         [132, 101,  85],\n",
      "         [128,  97,  81],\n",
      "         [128,  87,  72]],\n",
      "\n",
      "        [[202, 203, 199],\n",
      "         [207, 208, 204],\n",
      "         [205, 206, 202],\n",
      "         ...,\n",
      "         [126, 100,  87],\n",
      "         [126, 100,  87],\n",
      "         [129,  98,  83]],\n",
      "\n",
      "        [[203, 204, 200],\n",
      "         [205, 206, 202],\n",
      "         [208, 209, 205],\n",
      "         ...,\n",
      "         [125,  99,  86],\n",
      "         [127, 101,  88],\n",
      "         [134, 103,  88]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[199, 209, 206],\n",
      "         [199, 209, 206],\n",
      "         [199, 209, 206],\n",
      "         ...,\n",
      "         [141, 157, 189],\n",
      "         [141, 157, 189],\n",
      "         [141, 157, 189]],\n",
      "\n",
      "        [[198, 208, 205],\n",
      "         [198, 208, 205],\n",
      "         [199, 209, 206],\n",
      "         ...,\n",
      "         [140, 156, 188],\n",
      "         [140, 156, 188],\n",
      "         [140, 156, 188]],\n",
      "\n",
      "        [[198, 208, 205],\n",
      "         [198, 208, 205],\n",
      "         [199, 209, 206],\n",
      "         ...,\n",
      "         [139, 155, 187],\n",
      "         [139, 155, 187],\n",
      "         [140, 156, 188]]],\n",
      "\n",
      "\n",
      "       [[[202, 203, 199],\n",
      "         [202, 203, 199],\n",
      "         [202, 203, 199],\n",
      "         ...,\n",
      "         [117,  94,  80],\n",
      "         [117,  94,  80],\n",
      "         [123,  94,  78]],\n",
      "\n",
      "        [[203, 202, 199],\n",
      "         [203, 202, 199],\n",
      "         [203, 202, 199],\n",
      "         ...,\n",
      "         [122,  91,  76],\n",
      "         [127,  96,  81],\n",
      "         [136,  99,  79]],\n",
      "\n",
      "        [[203, 202, 199],\n",
      "         [203, 202, 199],\n",
      "         [203, 202, 199],\n",
      "         ...,\n",
      "         [127,  96,  81],\n",
      "         [123,  92,  77],\n",
      "         [133,  96,  76]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[196, 209, 207],\n",
      "         [197, 210, 208],\n",
      "         [197, 210, 208],\n",
      "         ...,\n",
      "         [161, 160, 168],\n",
      "         [161, 160, 168],\n",
      "         [161, 160, 168]],\n",
      "\n",
      "        [[196, 209, 207],\n",
      "         [197, 210, 208],\n",
      "         [197, 210, 208],\n",
      "         ...,\n",
      "         [159, 158, 166],\n",
      "         [160, 159, 167],\n",
      "         [160, 159, 167]],\n",
      "\n",
      "        [[196, 209, 207],\n",
      "         [197, 210, 208],\n",
      "         [197, 210, 208],\n",
      "         ...,\n",
      "         [158, 157, 165],\n",
      "         [159, 158, 166],\n",
      "         [160, 159, 167]]],\n",
      "\n",
      "\n",
      "       [[[204, 203, 200],\n",
      "         [204, 203, 200],\n",
      "         [204, 203, 200],\n",
      "         ...,\n",
      "         [198, 130,  95],\n",
      "         [196, 128,  93],\n",
      "         [199, 126,  92]],\n",
      "\n",
      "        [[203, 204, 200],\n",
      "         [203, 204, 200],\n",
      "         [203, 204, 200],\n",
      "         ...,\n",
      "         [203, 133,  91],\n",
      "         [201, 131,  89],\n",
      "         [202, 128,  90]],\n",
      "\n",
      "        [[203, 204, 200],\n",
      "         [203, 204, 200],\n",
      "         [203, 204, 200],\n",
      "         ...,\n",
      "         [203, 133,  91],\n",
      "         [203, 133,  91],\n",
      "         [206, 132,  94]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[192, 205, 203],\n",
      "         [193, 206, 204],\n",
      "         [192, 205, 203],\n",
      "         ...,\n",
      "         [183, 181, 180],\n",
      "         [182, 180, 179],\n",
      "         [180, 178, 177]],\n",
      "\n",
      "        [[192, 205, 203],\n",
      "         [193, 206, 204],\n",
      "         [192, 205, 203],\n",
      "         ...,\n",
      "         [177, 175, 174],\n",
      "         [177, 175, 174],\n",
      "         [176, 174, 173]],\n",
      "\n",
      "        [[193, 206, 204],\n",
      "         [193, 206, 204],\n",
      "         [192, 205, 203],\n",
      "         ...,\n",
      "         [165, 163, 162],\n",
      "         [166, 164, 163],\n",
      "         [165, 163, 162]]]], dtype=uint8)]}\n"
     ]
    }
   ],
   "source": [
    "from mmaction.apis.inferencers import MMAction2Inferencer\n",
    "\n",
    "# 参数设置：在Notebook中通过变量传递\n",
    "inputs = '../data/xian_video_dataset/pre/VID_20240905_104444.mp4'  # 视频文件或帧的路径\n",
    "vid_out_dir = '../data/xian_video_dataset/'  # 输出视频文件路径\n",
    "rec = '../configs/recognition/slowfast/slowfast_r50_8xb8-4x16x1-256e_xiandemo-rgb.py'  # 预训练的动作识别模型\n",
    "rec_weights = '../work_dirs/xiandemo_slowfast/epoch_256.pth'  # 权重文件\n",
    "label_file = '../data/xian_video_dataset/label_map.txt'  # 标签文件\n",
    "device = 'cuda:0'  # 使用的设备，例如 'cuda:0' 或 'cpu'\n",
    "batch_size = 1  # 推理的批次大小\n",
    "show = False  # 是否弹窗显示视频\n",
    "print_result = True  # 是否打印结果\n",
    "pred_out_file = '../data/xian_video_dataset/result.json'  # 推理结果保存文件\n",
    "\n",
    "# 初始化 inferencer\n",
    "mmaction2 = MMAction2Inferencer(\n",
    "    rec=rec,\n",
    "    rec_weights=rec_weights,\n",
    "    device=device,\n",
    "    label_file=label_file\n",
    ")\n",
    "\n",
    "# 推理调用\n",
    "results = mmaction2(\n",
    "    inputs=inputs,\n",
    "    vid_out_dir=vid_out_dir,\n",
    "    batch_size=batch_size,\n",
    "    show=show,\n",
    "    print_result=print_result,\n",
    "    pred_out_file=pred_out_file\n",
    ")\n",
    "\n",
    "# 如果需要在 Notebook 中显示结果，可以直接输出\n",
    "if print_result:\n",
    "    print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "2ff27afd-5477-4223-ac07-be0a03040f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../data/xian_video_dataset/output_video_3.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果有需要显示的视频结果，可以用 Notebook 的显示功能显示视频\n",
    "from IPython.display import Video\n",
    "# 输出视频的路径\n",
    "video_path = f'../data/xian_video_dataset/output_video_3.mp4'\n",
    "Video(video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2016a-734c-4a55-9392-e863e11efac9",
   "metadata": {},
   "source": [
    "## video show 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "bed9b8ee-1bf9-49dc-866b-fc44103ed6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../work_dirs/xiandemo_slowfast/epoch_256.pth\n",
      "The top-5 labels with corresponding scores are:\n",
      "si:  0.9999839067459106\n",
      "na:  9.942761607817374e-06\n",
      "zhuan:  4.7818434723012615e-06\n",
      "tie:  1.3897634971726802e-06\n",
      "en:  6.877859703990907e-08\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from operator import itemgetter\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "from mmengine import Config\n",
    "from mmaction.apis import inference_recognizer, init_recognizer\n",
    "from mmaction.visualization import ActionVisualizer\n",
    "\n",
    "# 参数直接在Notebook中定义\n",
    "config = '../configs/recognition/slowfast/slowfast_r50_8xb8-4x16x1-256e_xiandemo-rgb.py'  # 配置文件路径\n",
    "checkpoint = '../work_dirs/xiandemo_slowfast/epoch_256.pth'  # 检查点文件\n",
    "video = '../data/xian_video_dataset/val/3 (23).mp4'  # 视频文件或帧文件路径\n",
    "label_file = '../data/xian_video_dataset/label_map.txt'  # 标签文件路径\n",
    "out_filename = '../data/xian_video_dataset/output_video.mp4'  # 输出文件路径\n",
    "fps = 30  # 输出视频的FPS\n",
    "font_scale = None  # 字体大小\n",
    "font_color = 'white'  # 字体颜色\n",
    "target_resolution = (256, 256)  # 目标分辨率（宽，高）\n",
    "device = 'cuda:0'  # 使用的设备\n",
    "\n",
    "# 从配置文件中加载模型配置\n",
    "cfg = Config.fromfile(config)\n",
    "\n",
    "# 初始化模型\n",
    "model = init_recognizer(cfg, checkpoint, device=device)\n",
    "\n",
    "# 进行推理\n",
    "pred_result = inference_recognizer(model, video)\n",
    "\n",
    "# 获取预测结果\n",
    "pred_scores = pred_result.pred_score.tolist()\n",
    "score_tuples = tuple(zip(range(len(pred_scores)), pred_scores))\n",
    "score_sorted = sorted(score_tuples, key=itemgetter(1), reverse=True)\n",
    "top5_label = score_sorted[:5]\n",
    "\n",
    "# 读取标签文件\n",
    "labels = open(label_file).readlines()\n",
    "labels = [x.strip() for x in labels]\n",
    "results = [(labels[k[0]], k[1]) for k in top5_label]\n",
    "\n",
    "# 打印 top-5 标签及其对应分数\n",
    "print('The top-5 labels with corresponding scores are:')\n",
    "for result in results:\n",
    "    print(f'{result[0]}: ', result[1])\n",
    "\n",
    "# 使用moviepy可视化输出视频\n",
    "def get_output(\n",
    "    video_path: str,\n",
    "    out_filename: str,\n",
    "    data_sample: str,\n",
    "    labels: list,\n",
    "    fps: int = 30,\n",
    "    font_scale: Optional[str] = None,\n",
    "    font_color: str = 'white',\n",
    "    target_resolution: Optional[Tuple[int]] = None,\n",
    ") -> None:\n",
    "    \"\"\"使用 ``moviepy`` 生成输出视频或 gif。\n",
    "\n",
    "    Args:\n",
    "        video_path (str): 视频文件路径.\n",
    "        out_filename (str): 输出文件名.\n",
    "        datasample (str): 预测标签.\n",
    "        labels (list): 当前数据集的标签列表.\n",
    "        fps (int): 每秒读取的图片帧数. 默认为 30.\n",
    "        font_scale (float): 文本字体大小. 默认为 None.\n",
    "        font_color (str): 文本颜色. 默认为 ``white``.\n",
    "        target_resolution (Tuple[int], optional): 设置为 (w, h) 来调整帧的大小. 默认为 None.\n",
    "    \"\"\"\n",
    "    if video_path.startswith(('http://', 'https://')):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    # 初始化可视化器\n",
    "    out_type = 'gif' if osp.splitext(out_filename)[1] == '.gif' else 'video'\n",
    "    visualizer = ActionVisualizer()\n",
    "    visualizer.dataset_meta = dict(classes=labels)\n",
    "\n",
    "    text_cfg = {'colors': font_color}\n",
    "    if font_scale is not None:\n",
    "        text_cfg.update({'font_sizes': font_scale})\n",
    "\n",
    "    visualizer.add_datasample(\n",
    "        out_filename,\n",
    "        video_path,\n",
    "        data_sample,\n",
    "        draw_pred=True,\n",
    "        draw_gt=False,\n",
    "        text_cfg=text_cfg,\n",
    "        fps=fps,\n",
    "        out_type=out_type,\n",
    "        out_path=osp.join('demo', out_filename),\n",
    "        target_resolution=target_resolution)\n",
    "\n",
    "# 输出可视化结果\n",
    "if out_filename is not None:\n",
    "    if target_resolution is not None:\n",
    "        if target_resolution[0] == -1:\n",
    "            assert isinstance(target_resolution[1], int)\n",
    "            assert target_resolution[1] > 0\n",
    "        if target_resolution[1] == -1:\n",
    "            assert isinstance(target_resolution[0], int)\n",
    "            assert target_resolution[0] > 0\n",
    "        target_resolution = tuple(target_resolution)\n",
    "\n",
    "    get_output(\n",
    "        video,\n",
    "        out_filename,\n",
    "        pred_result,\n",
    "        labels,\n",
    "        fps=fps,\n",
    "        font_scale=font_scale,\n",
    "        font_color=font_color,\n",
    "        target_resolution=target_resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2da442d3-301c-4f74-a072-814f70afb551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../demo/data/xian_video_dataset/output_video.mp4\" controls  >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果你想在Notebook中显示生成的视频，可以使用以下代码\n",
    "from IPython.display import Video\n",
    "Video(\"../demo/data/xian_video_dataset/output_video.mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc02eb-8b44-4fce-8a3c-1abcf9b9f793",
   "metadata": {},
   "source": [
    "## video show 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8f51bfcd-6d9a-46ab-883c-24c24c57a71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: ../work_dirs/xiandemo_slowfast/epoch_256.pth\n",
      "labels: ['en', 'na', 'si', 'tie', 'zhuan']\n",
      "num_frames: 44\n",
      "temp_video_path: /root/project/research/action/mmaction2/demo_out/temp/tmps35kjlwh.mp4, temp_video.name: /root/project/research/action/mmaction2/demo_out/temp/tmps35kjlwh.mp4\n",
      "self.crop_size: (256, 256), imgs: 256, 455\n",
      "top5_label: [(1, 0.9997734427452087), (2, 0.0001676465617492795), (0, 4.221500057610683e-05), (3, 1.4668509720650036e-05), (4, 2.001506345550297e-06)]\n",
      "results: [(29, 'na')]\n"
     ]
    }
   ],
   "source": [
    "import os.path as osp\n",
    "from operator import itemgetter\n",
    "from typing import Optional, Tuple\n",
    "import tempfile\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "from mmengine import Config\n",
    "from mmaction.apis import inference_recognizer, init_recognizer\n",
    "from mmaction.visualization import ActionVisualizer\n",
    "\n",
    "# 参数直接在Notebook中定义\n",
    "config = '../configs/recognition/slowfast/slowfast_r50_8xb8-4x16x1-256e_xiandemo-rgb.py'  # 配置文件路径\n",
    "checkpoint = '../work_dirs/xiandemo_slowfast/epoch_256.pth'  # 检查点文件\n",
    "# video = '../data/xian_video_dataset/pre/VID_20240905_104444.mp4'  # 视频文件或帧文件路径\n",
    "video = '../data/xian_video_dataset/val/1 (1).mp4'  # 视频文件或帧文件路径\n",
    "label_file = '../data/xian_video_dataset/label_map.txt'  # 标签文件路径\n",
    "out_filename = '../data/xian_video_dataset/output_long_video.mp4'  # 输出文件路径\n",
    "fps = 30  # 输出视频的FPS\n",
    "font_scale = None  # 字体大小\n",
    "font_color = 'white'  # 字体颜色\n",
    "target_resolution = (256, 256)  # 目标分辨率（宽，高）\n",
    "device = 'cuda:0'  # 使用的设备\n",
    "\n",
    "clip_length = 30  # 每次推理使用的帧数\n",
    "interval = 1  # 帧间隔\n",
    "# 从配置文件中加载模型配置\n",
    "cfg = Config.fromfile(config)\n",
    "model = init_recognizer(cfg, checkpoint, device=device)\n",
    "\n",
    "# 获取标签\n",
    "labels = [x.strip() for x in open(label_file).readlines()]\n",
    "\n",
    "print(f\"labels: {labels}\")\n",
    "\n",
    "# 视频读取\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(video)\n",
    "num_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(f\"num_frames: {num_frames}\")\n",
    "frame_queue = deque(maxlen=clip_length)\n",
    "\n",
    "results = []\n",
    "temp_videos = []  # 存储临时短视频片段路径\n",
    "for i in range(num_frames):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 缓存帧用于分段推理\n",
    "    results = []\n",
    "    frame_queue.append(frame)\n",
    "    if len(frame_queue) == clip_length:\n",
    "        # 临时保存帧队列为视频文件\n",
    "        temp_dir = '/root/project/research/action/mmaction2/demo_out/temp'\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\", dir=temp_dir) as temp_video:\n",
    "            temp_video_path = os.path.join('./' , temp_video.name)\n",
    "            fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "            print(f\"temp_video_path: {temp_video_path}, temp_video.name: {temp_video.name}\")\n",
    "            video_writer = cv2.VideoWriter(temp_video_path, fourcc, fps, (frame.shape[1], frame.shape[0]))\n",
    "\n",
    "            for buffered_frame in frame_queue:\n",
    "                video_writer.write(buffered_frame)\n",
    "            video_writer.release()\n",
    "            \n",
    "        # 推理并保存结果\n",
    "        pred_result = inference_recognizer(model, temp_video_path)\n",
    "        pred_scores = pred_result.pred_score.tolist()\n",
    "        score_sorted = sorted(enumerate(pred_scores), key=itemgetter(1), reverse=True)\n",
    "        top5_label = score_sorted[:5]\n",
    "        print(f\"top5_label: {top5_label}\")\n",
    "        top_label = labels[score_sorted[0][0]]\n",
    "        results.append((i, top_label))\n",
    "        print(f\"results: {results}\")\n",
    "\n",
    "        # 重新打开临时视频文件以添加推理结果\n",
    "        video_writer = cv2.VideoWriter(temp_video_path, fourcc, fps, (frame.shape[1], frame.shape[0]))\n",
    "        for buffered_frame in frame_queue:\n",
    "            # 在每一帧中写入识别的动作类别\n",
    "            cv2.putText(buffered_frame, f\"Action: {top_label}\", (10, 30), \n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "            video_writer.write(buffered_frame)\n",
    "        video_writer.release()\n",
    "        \n",
    "        temp_videos.append(temp_video_path)  # 添加至临时视频列表\n",
    "        # 清空缓冲队列，开始新的片段\n",
    "        frame_queue.clear()  \n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f5806dc1-3c95-4ccf-863d-228e6ab6f05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "temp_videos: ['/root/project/research/action/mmaction2/demo_out/temp/tmps35kjlwh.mp4']\n"
     ]
    }
   ],
   "source": [
    "# 合并短视频为一个长视频\n",
    "clips = [VideoFileClip(temp_path) for temp_path in temp_videos]\n",
    "print(f\"temp_videos: {temp_videos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6f38a045-d713-448b-9024-654c77a9932f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video ../data/xian_video_dataset/output_long_video.mp4.\n",
      "Moviepy - Writing video ../data/xian_video_dataset/output_long_video.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready ../data/xian_video_dataset/output_long_video.mp4\n"
     ]
    }
   ],
   "source": [
    "final_video = concatenate_videoclips(clips)\n",
    "final_video.write_videofile(out_filename, codec=\"libx264\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "55195acf-0a43-47ff-861a-648b72d71d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 删除临时文件\n",
    "for temp_path in temp_videos:\n",
    "    os.remove(temp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "85617b9e-232f-456b-a118-11d1b17db81f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"../data/xian_video_dataset/output_long_video.mp4\" controls  width=\"640\"  height=\"480\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 如果你想在Notebook中显示生成的视频，可以使用以下代码\n",
    "from IPython.display import Video\n",
    "Video('../data/xian_video_dataset/output_long_video.mp4', width=640, height=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06d6f1a-7e78-45ba-bd60-adc873cb97e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
